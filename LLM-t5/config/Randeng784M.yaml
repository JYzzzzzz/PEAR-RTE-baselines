
# model
model_name_or_path: ./models/Randeng-T5-784M-MultiTask-Chinese
fp16: True    # 是否使用半精度训练，True时，GPU显存占用显著下降，速度加快

# input:
train_data_path: ./data/CMIM23-NOM1-RA_llm_form/triple_order__sample_expand__oneshot/train.json
dev_data_path: ./data/CMIM23-NOM1-RA_llm_form/triple_order__sample_expand__oneshot/dev.json
test_data_path: ./data/CMIM23-NOM1-RA_llm_form/triple_order__sample_expand__oneshot/test.json
special_tokens: []
max_length_input: 800
max_length_output: 1000

# output
output_dir: ./output/Randeng784M

# train
max_epoch: 2     # 训练的总数算epoch，但log、eval、save算step。程序中会换算。
per_device_train_batch_size: 4
gradient_accumulation_steps: 16    # 该值其实是 batch_size * step_num 之后的结果
checkpoint_num: 20   # 训练完希望获得的checkpoint数，save_step 与 eval_step 会根据该值计算。
logging_steps: 1000
learning_rate: 1e-5

# infer
per_device_eval_batch_size: 16
tokenizer_ids_to_str: Randeng-T5-77M-MultiTask-Chinese
rela_num_distribution: [[13], [13], [13], [13], [13], [13], [13], [13], [13], [13]]
    # 数据集特点：一个原句子样本对应的 包含 询问次数，每次询问关系数 的数组

# Randeng-T5-77M-MultiTask-Chinese:
#   - 自定义token前会加一个空格，自定义token后有些情况下会加1一个空格
#   - 空格保留、多空格会合并为单空格，'\n', '\r'会转化为空格，
#   - decode时，
